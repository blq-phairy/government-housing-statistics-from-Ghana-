### Step 1: Load the Data

Ensure that you have the dataset ready and placed in the working directory. You can load it using pandas:

```python
import pandas as pd

# Load the dataset
df = pd.read_csv('ghana_housing_statistics.csv')

# Display the first few rows of the dataset
print(df.head())
```

### Step 2: Data Wrangling

#### Handling Missing Values

```python
# Check for missing values
print("Missing values in each column:")
print(df.isnull().sum())

# Example: Fill missing values or drop columns with excessive nulls
df['amenities'].fillna('None', inplace=True)  # Fill missing amenities
df.drop(columns=['column_with_many_nans'], inplace=True)  # Drop columns with many NaNs if necessary
```

#### Removing Outliers

```python
# Identify outliers in price using the IQR method
Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1

# Filter out outliers
df = df[~((df['price'] < (Q1 - 1.5 * IQR)) | (df['price'] > (Q3 + 1.5 * IQR)))]
```

#### Feature Engineering

```python
# Create new features, e.g., property age
df['property_age'] = 2024 - df['year_built']

# Extract latitude and longitude if available
if 'location' in df.columns:
    df[['lat', 'lon']] = df['location'].str.split(',', expand=True).astype(float)

# You might want to check if 'location' was correctly split
print(df[['lat', 'lon']].head())
```

#### Handling Multicollinearity

```python
# Check correlations
correlation_matrix = df.corr()

# Identify features with high correlation with the target variable
high_corr_var = correlation_matrix[abs(correlation_matrix['price']) > 0.8].index
print("Highly correlated features with 'price':", high_corr_var)

# Drop highly correlated variables if necessary
df.drop(columns=high_corr_var, inplace=True)
```

### Step 3: Exploratory Data Analysis (EDA)

Perform EDA to understand the dataset and visualize key trends.

#### Visualizations

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Price distribution
plt.figure(figsize=(10, 5))
sns.histplot(df['price'], bins=30)
plt.title('Price Distribution of Properties')
plt.xlabel('Price (GHS/USD)')
plt.ylabel('Frequency')
plt.show()

# Boxplot for price by property type
plt.figure(figsize=(12, 6))
sns.boxplot(x='property_type', y='price', data=df)
plt.title('Price by Property Type')
plt.xlabel('Property Type')
plt.ylabel('Price (GHS/USD)')
plt.xticks(rotation=45)
plt.show()

# Heatmap for correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm")
plt.title('Correlation Matrix')
plt.show()
```

### Step 4: Modeling

Select a model and evaluate its performance.

#### Model Selection

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Define features and target variable
X = df.drop(columns=['price'])  # Features
y = df['price']  # Target variable

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit the model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
rmse = mean_squared_error(y_test, y_pred, squared=False)
mae = mean_absolute_error(y_test, y_pred)

print(f"Root Mean Squared Error: {rmse:.2f}")
print(f"Mean Absolute Error: {mae:.2f}")
```
